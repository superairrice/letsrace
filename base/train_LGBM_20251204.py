# === Django ì´ˆê¸°í™” ë¸”ë¡ (íŒŒì¼ ìµœìƒë‹¨ì— ìœ„ì¹˜) ===
import os
import sys
from pathlib import Path
from contextlib import closing

# í˜„ì¬ íŒŒì¼: /Users/Super007/Project/letsrace/base/train_LightGBM.py
# -> parent: base
# -> parent.parent: í”„ë¡œì íŠ¸ ë£¨íŠ¸(ì—¬ê¸°ì— manage.pyê°€ ìˆë‹¤ê³  ê°€ì •)
BASE_DIR = Path(__file__).resolve().parent.parent

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.path ì— ì¶”ê°€ (íŒ¨í‚¤ì§€ import ê°€ëŠ¥í•˜ë„ë¡)
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))

# â˜… manage.py ì— ìˆëŠ” ê°’ìœ¼ë¡œ ì •í™•íˆ ë§ì¶° ì£¼ì„¸ìš” â˜…
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "letsrace.settings")

import django

django.setup()
# === ì—¬ê¸°ê¹Œì§€ Django ì´ˆê¸°í™” ===

import pymysql
import pandas as pd
import lightgbm as lgb
from typing import List, Tuple


def _get_db_conf_from_django():
    """Try reading DB settings from Django if available.

    Returns a dict compatible with pymysql.connect or None if not available.
    """
    try:
        import django
        from django.conf import settings

        # If Django isn't setup yet (running as a script), set it up.
        if not settings.configured:
            # Best-effort: use env DJANGO_SETTINGS_MODULE if present
            if os.getenv("DJANGO_SETTINGS_MODULE"):
                django.setup()
            else:
                return None

        db = settings.DATABASES.get("default", {})
        if not db or db.get("ENGINE") != "django.db.backends.mysql":
            return None

        opts = db.get("OPTIONS", {})
        conf = {
            "host": db.get("HOST") or "127.0.0.1",
            "user": db.get("USER"),
            "password": db.get("PASSWORD"),
            "db": db.get("NAME"),
            "port": int(db.get("PORT") or 3306),
            "charset": opts.get("charset", "utf8mb4"),
            "cursorclass": pymysql.cursors.DictCursor,
            "autocommit": True,
        }
        # Propagate SSL if provided in Django options
        if "ssl" in opts:
            conf["ssl"] = opts["ssl"]
        return conf
    except Exception:
        return None


def _get_db_conf_from_env():
    """Read DB settings from environment variables (optionally loading .env).

    Supported vars: MYSQL_HOST, MYSQL_PORT, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DB, MYSQL_SSL_CA
    """
    # Lazy-load dotenv if present
    try:
        from dotenv import load_dotenv  # type: ignore

        load_dotenv()
    except Exception:
        pass

    host = os.getenv("MYSQL_HOST")
    user = os.getenv("MYSQL_USER")
    password = os.getenv("MYSQL_PASSWORD")
    db = os.getenv("MYSQL_DB")
    port = int(os.getenv("MYSQL_PORT") or 3306)
    ssl_ca = os.getenv("MYSQL_SSL_CA")

    if not all([host, user, password, db]):
        return None

    conf = {
        "host": host,
        "user": user,
        "password": password,
        "db": db,
        "port": port,
        "charset": "utf8mb4",
        "cursorclass": pymysql.cursors.DictCursor,
        "autocommit": True,
    }
    if ssl_ca:
        conf["ssl"] = {"ca": ssl_ca}
    return conf


def get_conn():
    """Obtain a PyMySQL connection using Django settings or env fallback.

    Order of precedence:
      1) Django DATABASES['default'] if configured and MySQL backend
      2) Environment variables (MYSQL_*)
    """
    conf = _get_db_conf_from_django() or _get_db_conf_from_env()

    if conf is None:
        # Final fallback (explicit values required). Raise a helpful error.
        raise RuntimeError(
            "Database configuration not found. Set DJANGO_SETTINGS_MODULE or export MYSQL_* env vars."
        )

    conn = pymysql.connect(**conf)
    try:
        conn.ping(reconnect=True)
    except Exception:
        pass
    return conn


def load_train_data_from_db(conn, from_date: str = "20231201") -> pd.DataFrame:
    sql = """
    SELECT
        e.rcity      AS ê²½ë§ˆì¥,
        e.rdate      AS ê²½ì£¼ì¼,
        e.rno        AS ê²½ì£¼ë²ˆí˜¸,
        x.distance   AS ê²½ì£¼ê±°ë¦¬,
        e.gate       AS ë§ˆë²ˆ,
        e.rank       AS ì˜ˆìƒìˆœìœ„1,
        e.r_pop      AS ì˜ˆìƒìˆœìœ„2,
        e.r_rank     AS ì‹¤ì œìˆœìœ„,
        e.alloc1r    AS ë‹¨ìŠ¹ì‹ë°°ë‹¹ìœ¨,
        e.alloc3r    AS ì—°ìŠ¹ì‹ë°°ë‹¹ìœ¨,
        /* ë³µìŠ¹ì‹ ë°°ë‹¹ìœ¨ */
        CAST(SUBSTRING(r.r2alloc,   3) AS DECIMAL(10, 0)) AS ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨,
        /* ì‚¼ë³µìŠ¹ì‹ ë°°ë‹¹ìœ¨ */
        CAST(SUBSTRING(r.r333alloc, 4) AS DECIMAL(10, 0)) AS ì‚¼ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨
    FROM The1.exp011 AS e
    LEFT JOIN The1.exp010 AS x
           ON x.rcity = e.rcity
          AND x.rdate = e.rdate
          AND x.rno   = e.rno
    LEFT JOIN The1.rec010 AS r
           ON r.rcity = e.rcity
          AND r.rdate = e.rdate
          AND r.rno   = e.rno
    WHERE e.rdate >= %s
    ORDER BY e.rcity, e.rdate, e.rno, e.gate
    """
    df = pd.read_sql(sql, conn, params=[from_date])
    return df


def save_lgb_model_to_db(conn, model: lgb.Booster, model_name: str, comment: str = ""):
    """LightGBM Boosterë¥¼ DBì— ë¬¸ìì—´ë¡œ ì €ì¥"""
    model_str = model.model_to_string()  # Booster ì „ì²´ë¥¼ textë¡œ ì§ë ¬í™”

    # Ensure table exists
    _ensure_lgb_models_table(conn)

    with conn.cursor() as cur:
        # ê°™ì€ model_name ë‚´ì—ì„œ version +1
        cur.execute(
            """
            SELECT IFNULL(MAX(version), 0) AS max_ver
            FROM lgb_models
            WHERE model_name = %s
            """,
            (model_name,),
        )
        row = cur.fetchone()
        next_ver = (row["max_ver"] or 0) + 1

        cur.execute(
            """
            INSERT INTO lgb_models (model_name, version, created_at, comment, model_text)
            VALUES (%s, %s, NOW(), %s, %s)
            """,
            (model_name, next_ver, comment, model_str),
        )
    conn.commit()
    print(f"â–¶ ëª¨ë¸ [{model_name}] v{next_ver} DB ì €ì¥ ì™„ë£Œ.")


def load_latest_lgb_model_from_db(conn, model_name: str) -> lgb.Booster:

    print(f"â–¶ DBì—ì„œ ëª¨ë¸ [{model_name}] ìµœì‹  ë²„ì „ ë¡œë“œ ì‹œë„...")

    """í•´ë‹¹ model_nameì˜ ìµœì‹  ë²„ì „ ëª¨ë¸ì„ DBì—ì„œ ì½ì–´ì„œ Booster ë³µì›"""

    with conn.cursor() as cur:
        cur.execute(
            """
            SELECT model_text
            FROM lgb_models
            WHERE model_name = %s
            ORDER BY version DESC
            LIMIT 1
            """,
            (model_name,),
        )
        row = cur.fetchone()
        if not row:
            raise ValueError(f"DBì— ëª¨ë¸ [{model_name}] ì´(ê°€) ì—†ìŠµë‹ˆë‹¤.")
        model_str = row["model_text"]

    booster = lgb.Booster(model_str=model_str)
    print(f"â–¶ ëª¨ë¸ [{model_name}] ìµœì‹  ë²„ì „ ë¡œë“œ ì™„ë£Œ.")
    return booster


def _ensure_lgb_models_table(conn):
    """Create lgb_models table if it does not exist."""
    sql = """
    CREATE TABLE IF NOT EXISTS lgb_models (
        id BIGINT AUTO_INCREMENT PRIMARY KEY,
        model_name VARCHAR(100) NOT NULL,
        version INT NOT NULL,
        created_at DATETIME NOT NULL,
        comment VARCHAR(255) NULL,
        model_text LONGTEXT NOT NULL,
        UNIQUE KEY unique_model_version (model_name, version),
        KEY idx_model_name_created (model_name, created_at)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """
    with conn.cursor() as cur:
        cur.execute(sql)
    conn.commit()


def train_lgb_for_top3_from_db(
    from_date: str = "20231201", model_name: str = "sb_top3_v1"
) -> lgb.Booster:
    """DBì—ì„œ í•™ìŠµ ë°ì´í„° ë¡œë“œ â†’ LightGBM í•™ìŠµ â†’ ëª¨ë¸ì„ DBì— ì €ì¥"""
    with closing(get_conn()) as conn:
        df = load_train_data_from_db(conn, from_date=from_date)

    # íƒ€ì… ì •ë¦¬
    df["ê²½ì£¼ì¼"] = df["ê²½ì£¼ì¼"].astype(str)
    df["ê²½ì£¼ë²ˆí˜¸"] = df["ê²½ì£¼ë²ˆí˜¸"].astype(int)
    df["ë§ˆë²ˆ"] = df["ë§ˆë²ˆ"].astype(int)

    df["ì˜ˆìƒìˆœìœ„1"] = df["ì˜ˆìƒìˆœìœ„1"].astype(int)
    df["ì˜ˆìƒìˆœìœ„2"] = df["ì˜ˆìƒìˆœìœ„2"].astype(int)

    df["ì‹¤ì œìˆœìœ„"] = df["ì‹¤ì œìˆœìœ„"].astype(int)

    if "ê²½ì£¼ê±°ë¦¬" in df.columns:
        df["ê²½ì£¼ê±°ë¦¬"] = df["ê²½ì£¼ê±°ë¦¬"].astype(int)

    # íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ (í•™ìŠµ/ì˜ˆì¸¡ ëª¨ë‘ ë™ì¼ ê·œì¹™ ì‚¬ìš©)
    df["rank_gap"] = df["ì˜ˆìƒìˆœìœ„2"] - df["ì˜ˆìƒìˆœìœ„1"]
    df["is_new"] = ((df["ì˜ˆìƒìˆœìœ„1"] >= 98) | (df["ì˜ˆìƒìˆœìœ„2"] >= 98)).astype(int)

    feature_cols = ["ì˜ˆìƒìˆœìœ„1", "ì˜ˆìƒìˆœìœ„2", "rank_gap", "is_new"]
    if "ê²½ì£¼ê±°ë¦¬" in df.columns:
        feature_cols.append("ê²½ì£¼ê±°ë¦¬")

    # label: ì‹¤ì œ 1~3ìœ„ ì•ˆì— ë“¤ì—ˆëŠ”ê°€?
    df["label_sb"] = (df["ì‹¤ì œìˆœìœ„"] <= 3).astype(int)

    train_set = lgb.Dataset(df[feature_cols], label=df["label_sb"])

    params = dict(
        objective="binary",
        boosting_type="gbdt",
        learning_rate=0.03,
        num_leaves=31,
        feature_fraction=0.9,
        bagging_fraction=0.9,
        bagging_freq=3,
        verbose=-1,
    )

    print("â–¶ LightGBM í•™ìŠµ ì‹œì‘...")
    model = lgb.train(params, train_set, num_boost_round=400)
    print("â–¶ í•™ìŠµ ì™„ë£Œ.")

    # í•™ìŠµí•œ ëª¨ë¸ DBì— ì €ì¥
    with closing(get_conn()) as conn:
        save_lgb_model_to_db(
            conn, model, model_name, comment=f"{from_date} ì´í›„ ë°ì´í„°ë¡œ í•™ìŠµ"
        )

    return model


def load_new_races_from_db(conn, from_date: str = "20251129") -> pd.DataFrame:
    """ì‹¤ì œìˆœìœ„ ì—†ì´, ìƒˆ ê²½ì£¼(ì˜ˆìƒìˆœìœ„ë§Œ ìˆëŠ”) ë°ì´í„° ë¡œë“œ"""
    sql = """
    SELECT
        e.rcity     AS ê²½ë§ˆì¥,
        e.rdate     AS ê²½ì£¼ì¼,
        e.rno       AS ê²½ì£¼ë²ˆí˜¸,
        x.distance  AS ê²½ì£¼ê±°ë¦¬,
        e.gate      AS ë§ˆë²ˆ,
        e.rank      AS ì˜ˆìƒìˆœìœ„1,
        e.r_pop     AS ì˜ˆìƒìˆœìœ„2
    FROM The1.exp011 AS e
    LEFT JOIN The1.exp010 AS x
           ON x.rcity = e.rcity
          AND x.rdate = e.rdate
          AND x.rno   = e.rno
    WHERE e.rdate >= %s
    ORDER BY e.rcity, e.rdate, e.rno, e.gate
    """
    df = pd.read_sql(sql, conn, params=[from_date])
    return df


def predict_top6_for_new_races(
    model: lgb.Booster, df_new: pd.DataFrame
) -> pd.DataFrame:
    """
    df_new: (ê²½ë§ˆì¥, ê²½ì£¼ì¼, ê²½ì£¼ë²ˆí˜¸, ê²½ì£¼ê±°ë¦¬, ë§ˆë²ˆ, ì˜ˆìƒìˆœìœ„1, ì˜ˆìƒìˆœìœ„2)
    return: ê²½ì£¼ë³„ ìƒìœ„ 6ë‘ (ë§ˆë²ˆ + í™•ë¥ )
    """
    d = df_new.copy()

    # íƒ€ì… ì •ë¦¬
    d["ê²½ì£¼ì¼"] = d["ê²½ì£¼ì¼"].astype(str)
    d["ê²½ì£¼ë²ˆí˜¸"] = d["ê²½ì£¼ë²ˆí˜¸"].astype(int)
    d["ë§ˆë²ˆ"] = d["ë§ˆë²ˆ"].astype(int)
    d["ì˜ˆìƒìˆœìœ„1"] = d["ì˜ˆìƒìˆœìœ„1"].astype(int)
    d["ì˜ˆìƒìˆœìœ„2"] = d["ì˜ˆìƒìˆœìœ„2"].astype(int)
    if "ê²½ì£¼ê±°ë¦¬" in d.columns:
        d["ê²½ì£¼ê±°ë¦¬"] = d["ê²½ì£¼ê±°ë¦¬"].astype(int)

    # í•™ìŠµê³¼ ë™ì¼í•œ feature ìƒì„±
    d["rank_gap"] = d["ì˜ˆìƒìˆœìœ„2"] - d["ì˜ˆìƒìˆœìœ„1"]
    d["is_new"] = ((d["ì˜ˆìƒìˆœìœ„1"] >= 98) | (d["ì˜ˆìƒìˆœìœ„2"] >= 98)).astype(int)

    feature_cols = ["ì˜ˆìƒìˆœìœ„1", "ì˜ˆìƒìˆœìœ„2", "rank_gap", "is_new"]
    if "ê²½ì£¼ê±°ë¦¬" in d.columns:
        feature_cols.append("ê²½ì£¼ê±°ë¦¬")

    d["p_sb"] = model.predict(d[feature_cols])

    # ê²½ì£¼ë³„ ìƒìœ„ 6ë‘ ì •ë¦¬
    rows = []
    for (track, date, rno), g in d.groupby(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸"]):
        g2 = g.sort_values("p_sb", ascending=False).head(6)

        rows.append(
            {
                "ê²½ë§ˆì¥": track,
                "ê²½ì£¼ì¼": date,
                "ê²½ì£¼ë²ˆí˜¸": rno,
                "ì„ íƒ_ìƒìœ„6_ë§ˆë²ˆ": ",".join(map(str, g2["ë§ˆë²ˆ"].tolist())),
                "ì„ íƒ_ìƒìœ„6_p_sb": ",".join(f"{x:.4f}" for x in g2["p_sb"].tolist()),
            }
        )

    result = pd.DataFrame(rows)
    return result


def predict_full_rank_for_new_races(
    model: lgb.Booster, df_new: pd.DataFrame
) -> pd.DataFrame:
    """
    ğŸ‘‰ df_new: (ê²½ë§ˆì¥, ê²½ì£¼ì¼, ê²½ì£¼ë²ˆí˜¸, ê²½ì£¼ê±°ë¦¬, ë§ˆë²ˆ, ì˜ˆìƒìˆœìœ„1, ì˜ˆìƒìˆœìœ„2)
    ğŸ‘‰ ì¶œë ¥: ê° ê²½ì£¼ë³„ ëª¨ë“  ë§ì— ëŒ€í•´
        - p_sb: ìƒìœ„ 3ìœ„ ì•ˆì— ë“¤ í™•ë¥ 
        - ì˜ˆìƒìˆœìœ„_LGBM: p_sb ë‚´ë¦¼ì°¨ìˆœ ê¸°ì¤€ ë­í‚¹(1,2,3,...)
    """
    d = df_new.copy()

    # íƒ€ì… ì •ë¦¬
    d["ê²½ì£¼ì¼"] = d["ê²½ì£¼ì¼"].astype(str)
    d["ê²½ì£¼ë²ˆí˜¸"] = d["ê²½ì£¼ë²ˆí˜¸"].astype(int)
    d["ë§ˆë²ˆ"] = d["ë§ˆë²ˆ"].astype(int)
    d["ì˜ˆìƒìˆœìœ„1"] = d["ì˜ˆìƒìˆœìœ„1"].astype(int)
    d["ì˜ˆìƒìˆœìœ„2"] = d["ì˜ˆìƒìˆœìœ„2"].astype(int)
    if "ê²½ì£¼ê±°ë¦¬" in d.columns:
        d["ê²½ì£¼ê±°ë¦¬"] = d["ê²½ì£¼ê±°ë¦¬"].astype(int)

    # í•™ìŠµ ì‹œì™€ ë™ì¼ Feature
    d["rank_gap"] = d["ì˜ˆìƒìˆœìœ„2"] - d["ì˜ˆìƒìˆœìœ„1"]
    d["is_new"] = ((d["ì˜ˆìƒìˆœìœ„1"] >= 98) | (d["ì˜ˆìƒìˆœìœ„2"] >= 98)).astype(int)

    feature_cols = ["ì˜ˆìƒìˆœìœ„1", "ì˜ˆìƒìˆœìœ„2", "rank_gap", "is_new"]
    if "ê²½ì£¼ê±°ë¦¬" in d.columns:
        feature_cols.append("ê²½ì£¼ê±°ë¦¬")

    # LightGBM í™•ë¥  ì˜ˆì¸¡
    d["p_sb"] = model.predict(d[feature_cols])

    # ê²½ì£¼ë³„ p_sb ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ì˜ˆìƒìˆœìœ„ ë¶€ì—¬
    d = d.sort_values(
        ["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸", "p_sb"],
        ascending=[True, True, True, False],
    )

    d["ì˜ˆìƒìˆœìœ„_LGBM"] = (
        d.groupby(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸"]).cumcount().astype(int) + 1
    )

    # ë³´ê¸° ì¢‹ê²Œ ì •ë ¬
    d = d.sort_values(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸", "ì˜ˆìƒìˆœìœ„_LGBM"]).reset_index(
        drop=True
    )

    return d


def predict_full_rank_for_new_races_and_update_db(
    conn, model: lgb.Booster, df_new: pd.DataFrame
) -> pd.DataFrame:
    """
    df_new: (ê²½ë§ˆì¥, ê²½ì£¼ì¼, ê²½ì£¼ë²ˆí˜¸, ê²½ì£¼ê±°ë¦¬, ë§ˆë²ˆ, ì˜ˆìƒìˆœìœ„1, ì˜ˆìƒìˆœìœ„2)

    ìˆ˜í–‰:
      1) LGBM p_sb ì˜ˆì¸¡
      2) ì˜ˆìƒìˆœìœ„_LGBM ê³„ì‚°
      3) exp011 í…Œì´ë¸”ì— m_score = p_sb, m_rank = ì˜ˆìƒìˆœìœ„_LGBM UPDATE ë°˜ì˜
      4) ì „ì²´ ì˜ˆì¸¡ DataFrame ë°˜í™˜
    """
    d = df_new.copy()

    # -----------------------------
    # 1) íƒ€ì… ì •ë¦¬
    # -----------------------------
    d["ê²½ì£¼ì¼"] = d["ê²½ì£¼ì¼"].astype(str)
    d["ê²½ì£¼ë²ˆí˜¸"] = d["ê²½ì£¼ë²ˆí˜¸"].astype(int)
    d["ë§ˆë²ˆ"] = d["ë§ˆë²ˆ"].astype(int)
    d["ì˜ˆìƒìˆœìœ„1"] = d["ì˜ˆìƒìˆœìœ„1"].astype(int)
    d["ì˜ˆìƒìˆœìœ„2"] = d["ì˜ˆìƒìˆœìœ„2"].astype(int)

    if "ê²½ì£¼ê±°ë¦¬" in d.columns:
        d["ê²½ì£¼ê±°ë¦¬"] = d["ê²½ì£¼ê±°ë¦¬"].astype(int)

    # -----------------------------
    # 2) Feature ìƒì„± (í•™ìŠµê³¼ ë™ì¼)
    # -----------------------------
    d["rank_gap"] = d["ì˜ˆìƒìˆœìœ„2"] - d["ì˜ˆìƒìˆœìœ„1"]
    d["is_new"] = ((d["ì˜ˆìƒìˆœìœ„1"] >= 98) | (d["ì˜ˆìƒìˆœìœ„2"] >= 98)).astype(int)

    feature_cols = ["ì˜ˆìƒìˆœìœ„1", "ì˜ˆìƒìˆœìœ„2", "rank_gap", "is_new"]
    if "ê²½ì£¼ê±°ë¦¬" in d.columns:
        feature_cols.append("ê²½ì£¼ê±°ë¦¬")

    # -----------------------------
    # 3) LGBM í™•ë¥  ì¶”ì • (ìƒìœ„3 ë“¤ í™•ë¥ )
    # -----------------------------
    d["p_sb"] = model.predict(d[feature_cols])

    # -----------------------------
    # 4) ê²½ì£¼ë³„ ì˜ì‚¬ìˆœìœ„ ìƒì„±
    # -----------------------------
    d = d.sort_values(
        ["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸", "p_sb"], ascending=[True, True, True, False]
    )
    d["ì˜ˆìƒìˆœìœ„_LGBM"] = d.groupby(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸"]).cumcount() + 1

    d = d.sort_values(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸", "ì˜ˆìƒìˆœìœ„_LGBM"]).reset_index(
        drop=True
    )

    # -----------------------------
    # 5) exp011 DB UPDATE ì²˜ë¦¬
    # -----------------------------
    with conn.cursor() as cur:
        sql = """
            UPDATE The1.exp011
            SET m_score = %s,   -- p_sb ê°’ ì €ì¥
                m_rank  = %s    -- LGBM ìˆœìœ„ ì €ì¥
            WHERE rcity = %s
              AND rdate = %s
              AND rno   = %s
              AND gate  = %s
        """
        update_params = [
            (
                float(row["p_sb"]),
                int(row["ì˜ˆìƒìˆœìœ„_LGBM"]),
                row["ê²½ë§ˆì¥"],
                row["ê²½ì£¼ì¼"],
                int(row["ê²½ì£¼ë²ˆí˜¸"]),
                int(row["ë§ˆë²ˆ"]),
            )
            for _, row in d.iterrows()
        ]

        cur.executemany(sql, update_params)
        conn.commit()

    print("â–¶ exp011 í…Œì´ë¸” m_score, m_rank ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

    return d


if __name__ == "__main__":
    conn = get_conn()

    try:
        # 1) DBì—ì„œ ìµœì‹  ëª¨ë¸ ë¡œë“œ ì‹œë„
        model = load_latest_lgb_model_from_db(conn, model_name="sb_top3_v1")
    except ValueError:
        print("â–¶ DBì— ëª¨ë¸ì´ ì—†ì–´ì„œ ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        conn.close()
        # 2) ì—†ìœ¼ë©´ í•™ìŠµ + ì €ì¥
        model = train_lgb_for_top3_from_db(
            from_date="20231201", model_name="sb_top3_v1"
        )
        # 3) ë‹¤ì‹œ ì—°ê²°í•´ì„œ ë¡œë“œ (ì¼ê´€ì„±ì„ ìœ„í•´)
        conn = get_conn()
        model = load_latest_lgb_model_from_db(conn, model_name="sb_top3_v1")

#     # 4) ìƒˆ ê²½ì£¼ ë¡œë“œ
#     df_new = load_new_races_from_db(conn, from_date="20251205")
#     conn.close()

#     # # 5) LGBM ìƒìœ„ 6ë‘ ì˜ˆì¸¡
#     # top6_df = predict_top6_for_new_races(model, df_new)
#     # print("â–¶ ìƒìœ„ 6ë‘ ì˜ˆì¸¡ ì˜ˆì‹œ")
#     # print(top6_df.head())

#     # # 6) LGBM ì „ì²´ ì˜ˆìƒìˆœìœ„(1ìœ„~ê¼´ì°Œ) ì˜ˆì¸¡
#     # # full_rank_df = predict_full_rank_for_new_races(model, df_new)
#     conn = get_conn()
#     full_rank_df = predict_full_rank_for_new_races_and_update_db(conn, model, df_new)
#     print("â–¶ ì „ì²´ ì˜ˆìƒìˆœìœ„ ì˜ˆì¸¡ ì˜ˆì‹œ")
#     print(full_rank_df.head(20))

#     # 7) CSVë¡œ ì €ì¥
#     # top6_df.to_csv(
#     #     "/Users/Super007/Documents/new_races_top6_lgb_from_db.csv",
#     #     index=False,
#     #     encoding="utf-8-sig",
#     # )
#     full_rank_df.to_csv(
#         "/Users/Super007/Documents/new_races_full_rank_lgb_from_db.csv",
#         index=False,
#         encoding="utf-8-sig",
#     )
#     print("â–¶ CSV ì €ì¥ ì™„ë£Œ:")
#     print("  - ìƒìœ„6ë‘:", "/Users/Super007/Documents/new_races_top6_lgb_from_db.csv")
#     print(
#         "  - ì „ì²´ìˆœìœ„:", "/Users/Super007/Documents/new_races_full_rank_lgb_from_db.csv"
#     )


def simulate_roi_with_lgb_rank(
    from_date: str = "20231201",
    model_name: str = "sb_top3_v1",
    exclude_new_races: bool = True,
    new_horse_threshold: int = 2,
    odds_cap: float = 500.0,
):
    """
    â–¶ í•™ìŠµ/ê²€ì¦ìš© ê³¼ê±° ë°ì´í„° + DB ì €ì¥ëœ LGBM ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ
       'ì˜ˆìƒìˆœìœ„_LGBM' ìƒìœ„ 6ë‘ë¥¼ ì¨ì„œ ì‚¼ë³µ/ë³µìŠ¹ ROI ì‹œë®¬ë ˆì´ì…˜.

    - from_date: í•™ìŠµ/í‰ê°€ì— ì‚¬ìš©í•  ë°ì´í„° ì‹œì‘ì¼(í¬í•¨)
    - model_name: DBì— ì €ì¥í•œ LightGBM ëª¨ë¸ ì´ë¦„
    - exclude_new_races:
        True  â†’ ì‹ ë§ˆê°€ new_horse_threshold ë‘ ì´ìƒì¸ ê²½ì£¼ëŠ” ì•„ì˜ˆ ì œì™¸
        False â†’ ì‹ ë§ˆ ê²½ì£¼ë„ í¬í•¨
    - new_horse_threshold:
        ì˜ˆ: 2 ë¼ë©´, "ì‹ ë§ˆê°€ 2ë‘ ì´ìƒ"ì¸ ê²½ì£¼ëŠ” ì œì™¸ ì¡°ê±´ì— í•´ë‹¹
    - odds_cap:
        ì‚¼ë³µ/ë³µìŠ¹ ë°°ë‹¹ì´ ì´ ê°’ ì´ìƒì´ë©´ í™˜ê¸‰ê¸ˆ 0 ì²˜ë¦¬ (ì´ˆê³ ë°°ë‹¹ ì»·)
    """
    # 1) DB ì—°ê²° + í•™ìŠµ/í‰ê°€ìš© ë°ì´í„° ë¡œë“œ
    conn = get_conn()
    df = load_train_data_from_db(conn, from_date=from_date)
    conn.close()

    # íƒ€ì… ì •ë¦¬
    df = df.copy()
    df["ê²½ì£¼ì¼"] = df["ê²½ì£¼ì¼"].astype(str)
    df["ê²½ì£¼ë²ˆí˜¸"] = df["ê²½ì£¼ë²ˆí˜¸"].astype(int)
    df["ë§ˆë²ˆ"] = df["ë§ˆë²ˆ"].astype(int)

    df["ì˜ˆìƒìˆœìœ„1"] = df["ì˜ˆìƒìˆœìœ„1"].astype(int)
    df["ì˜ˆìƒìˆœìœ„2"] = df["ì˜ˆìƒìˆœìœ„2"].astype(int)
    df["ì‹¤ì œìˆœìœ„"] = df["ì‹¤ì œìˆœìœ„"].astype(int)

    if "ê²½ì£¼ê±°ë¦¬" in df.columns:
        df["ê²½ì£¼ê±°ë¦¬"] = df["ê²½ì£¼ê±°ë¦¬"].astype(int)

    # 2) Feature ìƒì„± (í•™ìŠµ ë•Œì™€ ë™ì¼ ê·œì¹™)
    df["rank_gap"] = df["ì˜ˆìƒìˆœìœ„2"] - df["ì˜ˆìƒìˆœìœ„1"]
    df["is_new"] = ((df["ì˜ˆìƒìˆœìœ„1"] >= 98) | (df["ì˜ˆìƒìˆœìœ„2"] >= 98)).astype(int)

    feature_cols = ["ì˜ˆìƒìˆœìœ„1", "ì˜ˆìƒìˆœìœ„2", "rank_gap", "is_new"]
    if "ê²½ì£¼ê±°ë¦¬" in df.columns:
        feature_cols.append("ê²½ì£¼ê±°ë¦¬")

    # 3) DBì—ì„œ LGBM ëª¨ë¸ ë¡œë“œ
    conn = get_conn()
    model = load_latest_lgb_model_from_db(conn, model_name=model_name)
    conn.close()

    # 4) LGBM í™•ë¥  ì˜ˆì¸¡
    df["p_sb"] = model.predict(df[feature_cols])

    # 5) ê²½ì£¼ë³„ ì˜ˆìƒìˆœìœ„_LGBM (p_sb ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ 1,2,3,...)
    df = df.sort_values(
        ["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸", "p_sb"],
        ascending=[True, True, True, False],
    )

    df["ì˜ˆìƒìˆœìœ„_LGBM"] = (
        df.groupby(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸"]).cumcount().astype(int) + 1
    )

    # 6) ì‹ ë§ˆ ë‘ ìˆ˜ ì§‘ê³„(ê²½ì£¼ ë‹¨ìœ„)
    #    is_new == 1ì¸ ë§ˆí•„ ìˆ˜ (ì˜ˆìƒìˆœìœ„1/2 ì¤‘ 98 ì´ìƒ)
    race_new_count = (
        df.groupby(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸"])["is_new"].sum().reset_index()
    )
    race_new_count = race_new_count.rename(columns={"is_new": "ì‹ ë§ˆìˆ˜"})

    df = df.merge(
        race_new_count,
        on=["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸"],
        how="left",
    )

    if exclude_new_races:
        # ì‹ ë§ˆìˆ˜ê°€ ì¼ì • ê¸°ì¤€ ì´ìƒì¸ ê²½ì£¼ëŠ” ì•„ì˜ˆ ì œì™¸
        before = df["ê²½ì£¼ë²ˆí˜¸"].nunique()
        df = df[df["ì‹ ë§ˆìˆ˜"] < new_horse_threshold].copy()
        after = df["ê²½ì£¼ë²ˆí˜¸"].nunique()
        print(f"â–¶ ì‹ ë§ˆ {new_horse_threshold}ë‘ ì´ìƒ ê²½ì£¼ ì œì™¸: {before} â†’ {after} ê²½ì£¼")

    # 7) ê²½ì£¼ë³„ ì‚¼ë³µ/ë³µìŠ¹ ì ì¤‘ & í™˜ê¸‰ ê³„ì‚°
    race_rows = []

    for (track, date, rno), g in df.groupby(["ê²½ë§ˆì¥", "ê²½ì£¼ì¼", "ê²½ì£¼ë²ˆí˜¸"]):
        g = g.copy()

        # ìƒìœ„6 = ì˜ˆìƒìˆœìœ„_LGBM 1~6ìœ„
        selected = g[g["ì˜ˆìƒìˆœìœ„_LGBM"] <= 6]["ë§ˆë²ˆ"].tolist()
        selected_set = set(selected)

        # ì‹¤ì œ ìƒìœ„3 / ìƒìœ„2
        actual_top3 = g[g["ì‹¤ì œìˆœìœ„"] <= 3]["ë§ˆë²ˆ"].tolist()
        actual_top2 = g[g["ì‹¤ì œìˆœìœ„"] <= 2]["ë§ˆë²ˆ"].tolist()
        actual_top3_set = set(actual_top3)
        actual_top2_set = set(actual_top2)

        # ì ì¤‘ ì—¬ë¶€
        sb_hit = int(actual_top3_set.issubset(selected_set)) if actual_top3_set else 0
        bs_hit = int(actual_top2_set.issubset(selected_set)) if actual_top2_set else 0

        # ë°°ë‹¹ìœ¨ (ê²½ì£¼ë³„ë¡œ ë™ì¼ ê°€ì •)
        sb_odds = (
            float(g["ì‚¼ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨"].iloc[0]) if "ì‚¼ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨" in g.columns else 0.0
        )
        bs_odds = (
            float(g["ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨"].iloc[0]) if "ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨" in g.columns else 0.0
        )

        # 500ë°° ì´ìƒ ì»·
        if sb_hit == 1 and sb_odds < odds_cap:
            sb_refund = sb_odds * 100.0
        else:
            sb_refund = 0.0

        if bs_hit == 1 and bs_odds < odds_cap:
            bs_refund = bs_odds * 100.0
        else:
            bs_refund = 0.0

        race_rows.append(
            {
                "ê²½ë§ˆì¥": track,
                "ê²½ì£¼ì¼": date,
                "ê²½ì£¼ë²ˆí˜¸": rno,
                "ì‹ ë§ˆìˆ˜": int(g["ì‹ ë§ˆìˆ˜"].iloc[0]),
                "ì„ íƒ_ìƒìœ„6_LGBM_ë§ˆë²ˆ": ",".join(map(str, sorted(selected_set))),
                "ì‹¤ì œ_1_3ìœ„_ë§ˆë²ˆ": (
                    ",".join(map(str, sorted(actual_top3_set)))
                    if actual_top3_set
                    else ""
                ),
                "ì‹¤ì œ_1_2ìœ„_ë§ˆë²ˆ": (
                    ",".join(map(str, sorted(actual_top2_set)))
                    if actual_top2_set
                    else ""
                ),
                "ì‚¼ë³µ_ì ì¤‘": sb_hit,
                "ì‚¼ë³µ_í™˜ê¸‰ê¸ˆ": sb_refund,
                "ë³µìŠ¹_ì ì¤‘": bs_hit,
                "ë³µìŠ¹_í™˜ê¸‰ê¸ˆ": bs_refund,
                "ì‚¼ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨": sb_odds,
                "ë³µìŠ¹ì‹ë°°ë‹¹ìœ¨": bs_odds,
            }
        )

    race_df = pd.DataFrame(race_rows)

    # 8) ROI ê³„ì‚° (6ë³µì¡° ê¸°ì¤€)
    total_races = len(race_df)
    print(f"â–¶ ROI ê³„ì‚° ëŒ€ìƒ ê²½ì£¼ìˆ˜: {total_races}")

    # ì‚¼ë³µ: 6ë³µì¡° â†’ 20êµ¬ë© * 100ì› = 2,000ì› / ê²½ì£¼
    sb_bet_per_race = 20 * 100
    sb_total_bet = total_races * sb_bet_per_race
    sb_total_refund = race_df["ì‚¼ë³µ_í™˜ê¸‰ê¸ˆ"].sum()
    sb_roi = (
        (sb_total_refund - sb_total_bet) / sb_total_bet if sb_total_bet > 0 else 0.0
    )

    # ë³µìŠ¹: 6ë‘ 2ë§ˆë¦¬ ì¡°í•© â†’ 15êµ¬ë© * 100ì› = 1,500ì› / ê²½ì£¼
    bs_bet_per_race = 15 * 100
    bs_total_bet = total_races * bs_bet_per_race
    bs_total_refund = race_df["ë³µìŠ¹_í™˜ê¸‰ê¸ˆ"].sum()
    bs_roi = (
        (bs_total_refund - bs_total_bet) / bs_total_bet if bs_total_bet > 0 else 0.0
    )

    print("===================================")
    print(f"ì´ ê²½ì£¼ìˆ˜: {total_races}")
    print(
        f"[ì‚¼ë³µ] ì´ë² íŒ…ì•¡: {sb_total_bet:,}  ì´í™˜ê¸‰ì•¡: {sb_total_refund:,.1f}  ROI: {sb_roi:.3f}"
    )
    print(
        f"[ë³µìŠ¹] ì´ë² íŒ…ì•¡: {bs_total_bet:,}  ì´í™˜ê¸‰ì•¡: {bs_total_refund:,.1f}  ROI: {bs_roi:.3f}"
    )
    print("===================================")

    return race_df, sb_roi, bs_roi


if __name__ == "__main__":
    # 1) ë¨¼ì € LGBM ëª¨ë¸ì´ DBì— ì—†ë‹¤ë©´ í•œ ë²ˆ í•™ìŠµí•´ì„œ ì €ì¥
    #    (í•œ ë²ˆ ì €ì¥í•´ë‘ë©´ ì´í›„ì—ëŠ” ìƒëµ ê°€ëŠ¥)
    # train_lgb_for_top3_from_db(from_date="20241129", model_name="sb_top3_v1")

    # 2) LGBM ìˆœìœ„ ê¸°ë°˜ ì‚¼ë³µ/ë³µìŠ¹ ROI ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    race_df, sb_roi, bs_roi = simulate_roi_with_lgb_rank(
        from_date="20231201",
        model_name="sb_top3_v1",
        exclude_new_races=True,  # ì‹ ë§ˆ 2ë‘ ì´ìƒ ê²½ì£¼ ì œì™¸
        new_horse_threshold=2,
        odds_cap=500.0,  # 500ë°° ì´ìƒ í™˜ê¸‰ 0 ì²˜ë¦¬
    )

    # 3) ê²½ì£¼ë³„ raw ê²°ê³¼ ì €ì¥
    out_path = "/Users/Super007/Documents/lgb_rank_top6_roi_result.csv"
    race_df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"â–¶ ê²½ì£¼ë³„ LGBM ìˆœìœ„ ê¸°ë°˜ ROI ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: {out_path}")
